{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3802b1-c7cd-4f50-9ab4-0633de18c872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence_transformers in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from sentence_transformers) (4.39.3)\n",
      "Requirement already satisfied: tqdm in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from sentence_transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from sentence_transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from sentence_transformers) (0.22.2)\n",
      "Requirement already satisfied: Pillow in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from sentence_transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.1)\n",
      "Requirement already satisfied: sympy in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.7.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Downloading thinc-8.2.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from spacy) (24.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.7.5-cp311-cp311-macosx_11_0_arm64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl (488 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.4/488.4 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.2.5-cp311-cp311-macosx_11_0_arm64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.2.0-cp311-cp311-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.6/174.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, shellingham, pydantic-core, murmurhash, marisa-trie, cloudpathlib, click, catalogue, blis, annotated-types, srsly, pydantic, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed annotated-types-0.7.0 blis-0.7.11 catalogue-2.0.10 click-8.1.7 cloudpathlib-0.18.1 confection-0.1.5 cymem-2.0.8 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.2.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.8.2 pydantic-core-2.20.1 shellingham-1.5.4 smart-open-7.0.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.5 typer-0.12.3 wasabi-1.1.3 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install sentence_transformers\n",
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b252fd20-6ff8-4fa5-88c7-d0942fa4f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5db0b6f-7c60-49d7-bdfe-cc684a78c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: torchvision in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (0.19.0)\n",
      "Requirement already satisfied: torchaudio in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torch) (4.12.1)\n",
      "Requirement already satisfied: sympy in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/anujsinha/anaconda3/envs/IMT575/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efd2b0f1-2a5e-4ad7-a3c9-3869286cdd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "device_id = 4\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cpu\")\n",
    "# torch.cuda.set_device(torch.device(f'cuda:{device_id}' if torch.cuda.is_available() else 'cpu'))\n",
    "# print ('Cuda device %s | %s | %s/%sGB' % (torch.cuda.current_device(), torch.cuda.get_device_name(device_id),round(torch.cuda.memory_allocated(device_id)/1024**3,1),round(torch.cuda.memory_reserved(device_id)/1024**3,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81a94ef9-1d78-49a3-9bc6-d71b767f8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def spacy_tokenizer(doc):\n",
    "    tokens = nlp(doc)\n",
    "    return([token.lemma_.lower() for token in tokens if (token.text.isalnum() and not token.is_stop and not token.is_punct and not token.like_num)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08b37d40-7279-420d-896d-5f1d2d1892c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME = 'Newsfeed_raw.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a1aeba5-f7c2-4d6e-bcf0-e7b21264ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = pd.read_json(INPUT_FILE_NAME) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8c1063a-911b-4d52-afbe-7729f47acb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.dropna(subset=['text','title'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32d3bd0f-c58b-4ac6-99a7-2de8f8f2aca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "article_df.columns = ['id', 'date', 'title', 'text', 'story'] # drop story column if not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c79814d6-0c17-4881-a0fa-ea863804a664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>Chinese obstetrician admits to selling patient...</td>\n",
       "      <td>A Chinese doctor has admitted in court that sh...</td>\n",
       "      <td>91630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>Astronauts ring in the New Year at Times Square</td>\n",
       "      <td>Legions of onlookers watched the big screen in...</td>\n",
       "      <td>46837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>Trapped ship passengers can't go overboard wit...</td>\n",
       "      <td>But they can't party too hard because the resc...</td>\n",
       "      <td>38176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>Beyonce shuttle sample angers Nasa</td>\n",
       "      <td>TRAGEDY: The world watched in horror as the Ch...</td>\n",
       "      <td>95841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>Justice delays health law's birth control mandate</td>\n",
       "      <td>Only hours before the law was to take effect, ...</td>\n",
       "      <td>96661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date                                              title  \\\n",
       "0   0 2014-01-01  Chinese obstetrician admits to selling patient...   \n",
       "1   1 2014-01-01    Astronauts ring in the New Year at Times Square   \n",
       "2   2 2014-01-01  Trapped ship passengers can't go overboard wit...   \n",
       "3   3 2014-01-01                 Beyonce shuttle sample angers Nasa   \n",
       "4   4 2014-01-01  Justice delays health law's birth control mandate   \n",
       "\n",
       "                                                text  story  \n",
       "0  A Chinese doctor has admitted in court that sh...  91630  \n",
       "1  Legions of onlookers watched the big screen in...  46837  \n",
       "2  But they can't party too hard because the resc...  38176  \n",
       "3  TRAGEDY: The world watched in horror as the Ch...  95841  \n",
       "4  Only hours before the law was to take effect, ...  96661  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = article_df.head(1000)\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fd4a3ea-2f1d-45e7-9a96-dffc7791f626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "article_df['sentences'] = [[t] for t in article_df.title]\n",
    "article_df['sentence_counts'] = \"\"\n",
    "article_df['sentence_tokens'] = [[spacy_tokenizer(t)] for t in article_df.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d05a798-be4a-4b4f-ba0b-aa2e638b65d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "all_sentence_tokens = []\n",
    "for text in article_df['text'].values:\n",
    "    parsed = nlp(text)\n",
    "    sentences = []\n",
    "    sentence_tokens = []\n",
    "    for s in parsed.sents:\n",
    "        if len(s) > 1:\n",
    "            sentences.append(s.text)\n",
    "            sentence_tokens.append([token.lemma_.lower() for token in s if (token.text.isalnum() and not token.is_stop and not token.is_punct and not token.like_num)])\n",
    "    all_sentences.append(sentences)\n",
    "    all_sentence_tokens.append(sentence_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8fde869-f3b4-4da9-8e64-298ef0623476",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_sentences)):\n",
    "    article_df.at[i,'sentences'] = article_df.loc[i].sentences + all_sentences[i]\n",
    "    article_df.at[i,'sentence_tokens'] = article_df.loc[i].sentence_tokens + all_sentence_tokens[i]\n",
    "    article_df.at[i,'sentence_counts'] = len(article_df.loc[i].sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21166739-3d28-4b67-b156-7a6111ef6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')\n",
    "#https://www.sbert.net/docs/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dab1ed22-5c5b-4423-8cde-98d3d1c545a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['supreme',\n",
       "  'court',\n",
       "  'justice',\n",
       "  'delay',\n",
       "  'birth',\n",
       "  'control',\n",
       "  'mandate',\n",
       "  'health',\n",
       "  'care',\n",
       "  'law',\n",
       "  'catholic',\n",
       "  'group'],\n",
       " ['washington',\n",
       "  'hour',\n",
       "  'law',\n",
       "  'effect',\n",
       "  'supreme',\n",
       "  'court',\n",
       "  'justice',\n",
       "  'tuesday',\n",
       "  'block',\n",
       "  'implementation',\n",
       "  'president',\n",
       "  'barack',\n",
       "  'obama',\n",
       "  'health',\n",
       "  'care',\n",
       "  'law',\n",
       "  'force',\n",
       "  'religion',\n",
       "  'affiliate',\n",
       "  'organization',\n",
       "  'provide',\n",
       "  'health',\n",
       "  'insurance',\n",
       "  'employee',\n",
       "  'include',\n",
       "  'birth',\n",
       "  'control'],\n",
       " ['justice',\n",
       "  'sonia',\n",
       "  'sotomayor',\n",
       "  'decision',\n",
       "  'come',\n",
       "  'flurry',\n",
       "  'effort',\n",
       "  'catholic',\n",
       "  'affiliate',\n",
       "  'group',\n",
       "  'nation'],\n",
       " ['group',\n",
       "  'rush',\n",
       "  'federal',\n",
       "  'court',\n",
       "  'stop',\n",
       "  'wednesday',\n",
       "  'start',\n",
       "  'portion',\n",
       "  'affordable',\n",
       "  'care',\n",
       "  'act',\n",
       "  'know',\n",
       "  'obamacare'],\n",
       " ['sotomayor',\n",
       "  'act',\n",
       "  'request',\n",
       "  'organization',\n",
       "  'catholic',\n",
       "  'nun',\n",
       "  'denver',\n",
       "  'little',\n",
       "  'sisters',\n",
       "  'poor',\n",
       "  'home',\n",
       "  'aged'],\n",
       " ['request',\n",
       "  'emergency',\n",
       "  'stay',\n",
       "  'deny',\n",
       "  'early',\n",
       "  'day',\n",
       "  'federal',\n",
       "  'appeal',\n",
       "  'court'],\n",
       " ['government',\n",
       "  'temporarily',\n",
       "  'enjoin',\n",
       "  'enforce',\n",
       "  'applicant',\n",
       "  'contraceptive',\n",
       "  'coverage',\n",
       "  'requirement',\n",
       "  'impose',\n",
       "  'patient',\n",
       "  'protection',\n",
       "  'affordable',\n",
       "  'care',\n",
       "  'act',\n",
       "  'sotomayor',\n",
       "  'say',\n",
       "  'order'],\n",
       " ['sotomayor',\n",
       "  'new',\n",
       "  'york',\n",
       "  'tuesday',\n",
       "  'night',\n",
       "  'lead',\n",
       "  'final',\n",
       "  'countdown',\n",
       "  'push',\n",
       "  'ceremonial',\n",
       "  'button',\n",
       "  'signal',\n",
       "  'descent',\n",
       "  'times',\n",
       "  'square',\n",
       "  'new',\n",
       "  'year',\n",
       "  'eve',\n",
       "  'ball',\n",
       "  'give',\n",
       "  'government',\n",
       "  'official',\n",
       "  'est',\n",
       "  'friday',\n",
       "  'respond',\n",
       "  'order'],\n",
       " ['law',\n",
       "  'require',\n",
       "  'employer',\n",
       "  'provide',\n",
       "  'insurance',\n",
       "  'cover',\n",
       "  'range',\n",
       "  'preventive',\n",
       "  'care',\n",
       "  'free',\n",
       "  'charge',\n",
       "  'include',\n",
       "  'contraception'],\n",
       " ['catholic', 'church', 'prohibit', 'use', 'contraceptive'],\n",
       " ['obama',\n",
       "  'administration',\n",
       "  'craft',\n",
       "  'compromise',\n",
       "  'accommodation',\n",
       "  'attempt',\n",
       "  'create',\n",
       "  'buffer',\n",
       "  'religiously',\n",
       "  'affiliate',\n",
       "  'hospital',\n",
       "  'university',\n",
       "  'social',\n",
       "  'service',\n",
       "  'group',\n",
       "  'oppose',\n",
       "  'birth',\n",
       "  'control'],\n",
       " ['law',\n",
       "  'require',\n",
       "  'insurer',\n",
       "  'health',\n",
       "  'plan',\n",
       "  'outside',\n",
       "  'administrator',\n",
       "  'pay',\n",
       "  'birth',\n",
       "  'control',\n",
       "  'coverage',\n",
       "  'create',\n",
       "  'way',\n",
       "  'reimburse'],\n",
       " ['work',\n",
       "  'nun',\n",
       "  'sign',\n",
       "  'form',\n",
       "  'authorize',\n",
       "  'insurance',\n",
       "  'company',\n",
       "  'provide',\n",
       "  'contraceptive',\n",
       "  'coverage',\n",
       "  'violate',\n",
       "  'belief',\n",
       "  'argue',\n",
       "  'attorney',\n",
       "  'mark',\n",
       "  'rienzi'],\n",
       " ['emergency',\n",
       "  'injunction',\n",
       "  'mother',\n",
       "  'provincial',\n",
       "  'loraine',\n",
       "  'marie',\n",
       "  'maguire',\n",
       "  'decide',\n",
       "  'course',\n",
       "  'action',\n",
       "  'sign',\n",
       "  'submit',\n",
       "  'self',\n",
       "  'certification',\n",
       "  'form',\n",
       "  'violate',\n",
       "  'religious',\n",
       "  'belief',\n",
       "  'b',\n",
       "  'refuse',\n",
       "  'sign',\n",
       "  'form',\n",
       "  'pay',\n",
       "  'ruinous',\n",
       "  'fine',\n",
       "  'rienzi',\n",
       "  'say'],\n",
       " ['white', 'house', 'comment', 'order', 'tuesday', 'night'],\n",
       " ['statement',\n",
       "  'tuesday',\n",
       "  'night',\n",
       "  'rienzi',\n",
       "  'say',\n",
       "  'delighted',\n",
       "  'sotomayor',\n",
       "  'order'],\n",
       " ['government', 'lot', 'way', 'deliver', 'contraceptive', 'people', 'say'],\n",
       " ['need', 'force', 'nun', 'participate'],\n",
       " ['sotomayor',\n",
       "  'decision',\n",
       "  'delay',\n",
       "  'contraceptive',\n",
       "  'portion',\n",
       "  'law',\n",
       "  'join',\n",
       "  'court',\n",
       "  'appeals',\n",
       "  'district',\n",
       "  'columbia',\n",
       "  'circuit',\n",
       "  'issue',\n",
       "  'emergency',\n",
       "  'stay',\n",
       "  'catholic',\n",
       "  'affiliate',\n",
       "  'group',\n",
       "  'challenge',\n",
       "  'contraceptive',\n",
       "  'provision',\n",
       "  'include',\n",
       "  'archdiocese',\n",
       "  'washington',\n",
       "  'catholic',\n",
       "  'university'],\n",
       " ['judge',\n",
       "  'judge',\n",
       "  'panel',\n",
       "  'decision',\n",
       "  'judge',\n",
       "  'david',\n",
       "  'tatel',\n",
       "  'say',\n",
       "  'deny',\n",
       "  'motion'],\n",
       " ['believe',\n",
       "  'appellant',\n",
       "  'unlikely',\n",
       "  'prevail',\n",
       "  'claim',\n",
       "  'challenge',\n",
       "  'provision',\n",
       "  'impose',\n",
       "  'substantial',\n",
       "  'burden',\n",
       "  'religious',\n",
       "  'freedom',\n",
       "  'restoration',\n",
       "  'act',\n",
       "  'deny',\n",
       "  'application',\n",
       "  'injunction',\n",
       "  'pende',\n",
       "  'appeal',\n",
       "  'tatel',\n",
       "  'say'],\n",
       " ['archdiocese', 'praise', 'appeal', 'court', 'action', 'statement'],\n",
       " ['action',\n",
       "  'court',\n",
       "  'appeals',\n",
       "  'circuit',\n",
       "  'line',\n",
       "  'ruling',\n",
       "  'court',\n",
       "  'country',\n",
       "  'hold',\n",
       "  'hhs',\n",
       "  'mandate',\n",
       "  'impose',\n",
       "  'substantial',\n",
       "  'impermissible',\n",
       "  'burden',\n",
       "  'free',\n",
       "  'exercise',\n",
       "  'religion',\n",
       "  'archdiocese',\n",
       "  'say'],\n",
       " ['decision',\n",
       "  'vindicate',\n",
       "  'pledge',\n",
       "  'catholic',\n",
       "  'bishop',\n",
       "  'stand',\n",
       "  'united',\n",
       "  'resolute',\n",
       "  'defence',\n",
       "  'sacred',\n",
       "  'freedom',\n",
       "  'religious',\n",
       "  'liberty'],\n",
       " ['supreme',\n",
       "  'court',\n",
       "  'decide',\n",
       "  'rule',\n",
       "  'business',\n",
       "  'use',\n",
       "  'religious',\n",
       "  'objection',\n",
       "  'escape',\n",
       "  'requirement',\n",
       "  'cover',\n",
       "  'birth',\n",
       "  'control',\n",
       "  'employee'],\n",
       " ['case',\n",
       "  'involve',\n",
       "  'hobby',\n",
       "  'lobby',\n",
       "  'oklahoma',\n",
       "  'city',\n",
       "  'base',\n",
       "  'art',\n",
       "  'craft',\n",
       "  'chain',\n",
       "  'time',\n",
       "  'employee',\n",
       "  'expect',\n",
       "  'argue',\n",
       "  'march',\n",
       "  'decide',\n",
       "  'summer'],\n",
       " ['follow', 'jesse', 'holland', 'twitter']]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df['sentence_tokens'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85e27963-006a-4141-8533-eca92718187a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "errors = []\n",
    "k = 0\n",
    "for sentences in article_df['sentences']:\n",
    "    try:\n",
    "        embedding = st_model.encode(sentences)\n",
    "        embeddings.append(embedding)\n",
    "    except Exception as e:\n",
    "        errors.append(k)\n",
    "        print(\"error at\", k, e)\n",
    "\n",
    "    k = k + 1\n",
    "    if k % 100 ==0:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74d29cf7-956d-404b-9c5b-d563c36b6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df['sentence_embds'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7d6f557-687b-4665-96dc-6b00b7ed2d86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noise_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (idx,row) \u001b[38;5;129;01min\u001b[39;00m article_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnoise_list\u001b[49m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      4\u001b[0m             article_df\u001b[38;5;241m.\u001b[39mdrop(idx, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'noise_list' is not defined"
     ]
    }
   ],
   "source": [
    "# for (idx,row) in article_df.iterrows():\n",
    "#     for n in noise_list:\n",
    "#         if n in row['sentences']:\n",
    "#             article_df.drop(idx, inplace = True)\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1481c0c0-44d2-4560-871c-11a29b728278",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df['date'] = [str(k)[:10] for k in article_df['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd1b1768-898c-4ea8-894f-68eac178e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.sort_values(by=['date'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1206cea3-f075-4746-a53c-ffecb6ff34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.reset_index(inplace= True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d0ac961-be22-478d-ac56-b0476e6b2845",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df['id'] = article_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fdc2c1d-b75b-482e-8574-eccc4c80a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE_NAME = 'Newsfeed_raw_output.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1209cbf7-bd1c-4ffb-b923-bf4002429d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.to_json(OUTPUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb6627-8c30-4ac4-94e5-1b9b9b6e9f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMT575",
   "language": "python",
   "name": "imt575"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
